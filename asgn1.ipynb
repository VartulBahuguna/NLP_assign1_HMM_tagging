{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in e:\\python\\python38\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in e:\\python\\python38\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\python\\python38\\lib\\site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: tqdm in e:\\python\\python38\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: joblib in e:\\python\\python38\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in e:\\python\\python38\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'e:\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\VARTUL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\VARTUL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list(brown.tagged_sents(tagset = 'universal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add start and end tags:\n",
    "def add_start_end_tag(sentences_original):\n",
    "    sentences=[\"\"]*len(sentences_original)\n",
    "    for i in range(len(sentences_original)):\n",
    "        sentences[i]=[(\"<start>\",\"<start>\")]+sentences_original[i]+[(\"<end>\",\"<end>\")]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a tag, what is its index : tags dict {\"tag\" : \"tag_index\"}\n",
    "#given an index what is the tag : tags_reverse list of string\n",
    "#count of each tag: tag_count\n",
    "def creat_tags_meta(sentences):\n",
    "    tags_dict={}\n",
    "    tags_reverse=[\"\"]*100000\n",
    "    cnt = 0\n",
    "    tag_count=[]\n",
    "    for i in range(len(sentences)):\n",
    "        for j in sentences[i]:\n",
    "            if j[1] not in tags_dict:\n",
    "                tags_dict[j[1]] = cnt\n",
    "                tags_reverse[cnt]=j[1]\n",
    "                tag_count.append(0)\n",
    "                cnt += 1\n",
    "            tag_count[tags_dict[j[1]]]+=1\n",
    "\n",
    "    return (tags_dict, tags_reverse, tag_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating transition matrix\n",
    "def create_transition_matrix(sentences, tags_dict, tag_count):\n",
    "    bigram_matrix = []\n",
    "    transition_matrix = []\n",
    "    total_tags = len(tag_count)\n",
    "    for i in range(total_tags): \n",
    "        bigram_matrix.append([0]*total_tags)\n",
    "        transition_matrix.append([0]*total_tags)\n",
    "\n",
    "    #creating a bigram matrix\n",
    "    for sentence in sentences:\n",
    "        for j in range(len(sentence)-1):\n",
    "            bigram_matrix[tags_dict[sentence[j][1]]][tags_dict[sentence[j+1][1]]]+=1\n",
    "    # print(bigram_matrix)\n",
    "    \n",
    "    #create transition matrix A\n",
    "    for i in range(total_tags):\n",
    "        for j in range(total_tags):\n",
    "            transition_matrix[i][j]=bigram_matrix[i][j]/tag_count[i]\n",
    "    # print(transition_matrix)\n",
    "    \n",
    "    return (transition_matrix, bigram_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word to index number\n",
    "def create_word_dict(sentences):\n",
    "\n",
    "    idx = 0\n",
    "    word_dict={}\n",
    "    # word_dict[\"<start>\"]=idx\n",
    "    for sentence in sentences:\n",
    "        for tup in sentence:\n",
    "            if tup[0] not in word_dict:\n",
    "                \n",
    "                word_dict[tup[0]]=idx\n",
    "                idx += 1\n",
    "    word_dict[\"<unknown>\"]=idx\n",
    "    # print('idx--------------------------------', idx)\n",
    "    # print('worddict--------------------------------', len(word_dict))\n",
    "    return word_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emmision_matrix(word_dict, tags_dict, tag_count, sentences):\n",
    "    # words = list(brown.words())\n",
    "    words_cnt = len(word_dict)\n",
    "    total_tags = len(tags_dict)\n",
    "    emmision_matrix = []\n",
    "    \n",
    "    for i in range(words_cnt):\n",
    "        emmision_matrix.append([0]*total_tags)\n",
    "    # print(\"--------------------------------------\",len(word_dict))\n",
    "    # print(\"------------------------\", len(emmision_matrix))\n",
    "    # print(\"------------------------\", word_dict['<unknown>'])\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        for j in sentence:\n",
    "            emmision_matrix[word_dict[j[0]]][tags_dict[j[1]]]+=1\n",
    "\n",
    "    \n",
    "    for i in range(words_cnt):\n",
    "        for j in range(total_tags):\n",
    "            emmision_matrix[i][j]/=tag_count[j]\n",
    "    # print(\"------------------------\", emmision_matrix[word_dict['unknown'])\n",
    "\n",
    "    # handling missing case\n",
    "    aux=[0]*len(tags_dict.keys())\n",
    "    aux[tags_dict['NOUN']]=0.5\n",
    "    aux[tags_dict['VERB']]=0.25\n",
    "    aux[tags_dict['ADV']]=0.125\n",
    "    aux[tags_dict['ADJ']]=0.125\n",
    "    # print(aux)\n",
    "    emmision_matrix[word_dict['<unknown>']]=aux\n",
    "    \n",
    "\n",
    "    return emmision_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(sentence):\n",
    "    new_sentence=[]\n",
    "    for i in sentence:\n",
    "        new_sentence.append(i[0])\n",
    "\n",
    "    # print(new_sentence)\n",
    "\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMM_logic(input, transition_matrix, emmision_matrix, tags_dict, word_dict):\n",
    "    tags_output=[\"<start>\"]\n",
    "    last_prob = 1\n",
    "    \n",
    "    for i in range(1, len(input)):\n",
    "        tag = tags_output[i-1]\n",
    "        curr_ob = input[i]\n",
    "        if curr_ob not in word_dict:\n",
    "            curr_ob=\"<unknown>\"\n",
    "\n",
    "            \n",
    "        max_prob = 0\n",
    "        # print(emmision_matrix[word_dict[curr_ob]])\n",
    "        curr_tag = \"\"\n",
    "        for j in tags_dict:\n",
    "            temp = transition_matrix[tags_dict[tag]][tags_dict[j]]*emmision_matrix[word_dict[curr_ob]][tags_dict[j]]*last_prob\n",
    "            if(temp >= max_prob):\n",
    "                curr_tag = j\n",
    "                max_prob = temp\n",
    "        last_prob = max_prob\n",
    "        tags_output.append(curr_tag)\n",
    "        # print(curr_tag)\n",
    "\n",
    "    return tags_output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_original = brown.tagged_sents(tagset='universal')\n",
    "sentences = add_start_end_tag(sentences_original)\n",
    "# (tags_dict, tags_reverse, tag_count) = creat_tags_meta(sentences)\n",
    "# (transition_matrix, bigram_matrix) = create_transition_matrix(sentences, tags_dict, tag_count)\n",
    "# word_dict = create_word_dict(sentences)\n",
    "# emmision_matrix = create_emmision_matrix(word_dict, tags_dict, tag_count, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confusion_matrix(cm,actual,predicted,tags_dict):\n",
    "    for i in range(len(actual)):\n",
    "        cm[tags_dict[actual[i][1]]][tags_dict[predicted[i]]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input=[\"<start>\",\"do\",\"you\",\"know\",\"who\",\"is\",\"vartul\", \"?\", \"<end>\"]\n",
    "# tags_output = HMM_logic(input, transition_matrix, emmision_matrix, tags_dict, word_dict)\n",
    "# print(tags_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits data in k sets:\n",
    "def k_splits (k, data):\n",
    "    splits = {}\n",
    "    n = len(data)//k\n",
    "    for i in range(0, k):\n",
    "        i = int(i)\n",
    "        if(i+1 == k):\n",
    "            splits[i]= data[n*i : ]\n",
    "        splits[i]=data[n*i : n*(i+1)]\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_set=k_splits(5,sentences)\n",
    "keys=list(cross_validation_set.keys())\n",
    "\n",
    "for i in keys:\n",
    "    train_data=[]\n",
    "    for k in cross_validation_set.keys():\n",
    "        if k!=i:\n",
    "            train_data+=cross_validation_set[k]\n",
    "\n",
    "    test_data=cross_validation_set[i]\n",
    "    # print(test_data[1:20])\n",
    "    # break\n",
    "    (tags_dict, tags_reverse, tag_count) = creat_tags_meta(train_data)\n",
    "    confusion_matrix=[]\n",
    "    for i in range(len(tag_count)):\n",
    "        confusion_matrix.append([0]*len(tag_count))\n",
    "    # print(tags_dict)\n",
    "    (transition_matrix, bigram_matrix) = create_transition_matrix(train_data, tags_dict, tag_count)\n",
    "    word_dict = create_word_dict(train_data)\n",
    "    emmision_matrix = create_emmision_matrix(word_dict,  tags_dict, tag_count, train_data)\n",
    "    # c=0\n",
    "    for sen in test_data:\n",
    "        # if c == 10:\n",
    "        #     break\n",
    "        # c+=1\n",
    "        # print(remove_tags(sen))\n",
    "        tags_output = HMM_logic(remove_tags(sen), transition_matrix, emmision_matrix, tags_dict, word_dict)\n",
    "        # print(len(remove_tags(sen)),len(tags_output))\n",
    "        build_confusion_matrix(confusion_matrix,sen,tags_output,tags_dict)\n",
    "        \n",
    "    print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9483230797820835\n"
     ]
    }
   ],
   "source": [
    "actual=0\n",
    "count=0\n",
    "for i in range(0,len(confusion_matrix)):\n",
    "    actual+=confusion_matrix[i][i]\n",
    "    count+=sum(confusion_matrix[i])\n",
    "actual/=5\n",
    "count/=5\n",
    "print(actual/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(confusion_matrix):\n",
    "    recall = []\n",
    "    n = len(confusion_matrix)\n",
    "    for i in range(0,n):\n",
    "        sum = 0\n",
    "        for j in range(0,len(confusion_matrix[i])):\n",
    "            sum+=confusion_matrix[i][j]\n",
    "        recall.append(confusion_matrix[i][i]/sum)\n",
    "\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(confusion_matrix):\n",
    "    precision = []\n",
    "    n = len(confusion_matrix)\n",
    "    for i in range(0,n):\n",
    "        sum = 0\n",
    "        for j in range(0,len(confusion_matrix[i])):\n",
    "            sum+=confusion_matrix[j][i]\n",
    "        precision.append(confusion_matrix[i][i]/sum)\n",
    "\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall :  [1.0, 0.9807788317523715, 0.9578607111372318, 0.8561136478944699, 0.9473537518193924, 0.9052294672887057, 0.9998968469552659, 0.9997384025113359, 0.8352267210408778, 0.995647807164379, 0.8195915860586519, 0.941598955310505, 0.9850746268656716, 0.1270718232044199]\n"
     ]
    }
   ],
   "source": [
    "print(\"recall : \", recall(confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  [1.0, 0.9651191353475804, 0.9133090501541048, 0.874300518134715, 0.9712353557481664, 0.8959944158075601, 1.0, 1.0, 0.918918918918919, 0.9868923179027709, 0.7654143963292228, 0.9971573448063922, 0.8734491315136477, 0.3484848484848485]\n"
     ]
    }
   ],
   "source": [
    "print(\"precision : \", precision(confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
