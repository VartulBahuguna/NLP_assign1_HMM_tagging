{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in e:\\python\\python38\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in e:\\python\\python38\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\python\\python38\\lib\\site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: tqdm in e:\\python\\python38\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: joblib in e:\\python\\python38\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in e:\\python\\python38\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'e:\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\VARTUL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\VARTUL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list(brown.tagged_sents(tagset = 'universal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add start and end tags:\n",
    "def add_start_end_tag(sentences_original):\n",
    "    sentences=[\"\"]*len(sentences_original)\n",
    "    for i in range(len(sentences_original)):\n",
    "        sentences[i]=[(\"<start>\",\"<start>\")]+sentences_original[i]+[(\"<end>\",\"<end>\")]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a tag, what is its index : tags dict {\"tag\" : \"tag_index\"}\n",
    "#given an index what is the tag : tags_reverse list of string\n",
    "#count of each tag: tag_count\n",
    "def creat_tags_meta(sentences):\n",
    "    tags_dict={}\n",
    "    tags_reverse=[\"\"]*100000\n",
    "    cnt = 0\n",
    "    tag_count=[]\n",
    "    for i in range(len(sentences)):\n",
    "        for j in sentences[i]:\n",
    "            if j[1] not in tags_dict:\n",
    "                tags_dict[j[1]] = cnt\n",
    "                tags_reverse[cnt]=j[1]\n",
    "                tag_count.append(0)\n",
    "                cnt += 1\n",
    "            tag_count[tags_dict[j[1]]]+=1\n",
    "\n",
    "    return (tags_dict, tags_reverse, tag_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating transition matrix\n",
    "def create_transition_matrix(sentences, tags_dict, tag_count):\n",
    "    bigram_matrix = []\n",
    "    transition_matrix = []\n",
    "    total_tags = len(tag_count)\n",
    "    for i in range(total_tags): \n",
    "        bigram_matrix.append([0]*total_tags)\n",
    "        transition_matrix.append([0]*total_tags)\n",
    "\n",
    "    #creating a bigram matrix\n",
    "    for sentence in sentences:\n",
    "        for j in range(len(sentence)-1):\n",
    "            bigram_matrix[tags_dict[sentence[j][1]]][tags_dict[sentence[j+1][1]]]+=1\n",
    "    # print(bigram_matrix)\n",
    "    \n",
    "    #create transition matrix A\n",
    "    for i in range(total_tags):\n",
    "        for j in range(total_tags):\n",
    "            transition_matrix[i][j]=bigram_matrix[i][j]/tag_count[i]\n",
    "    # print(transition_matrix)\n",
    "    \n",
    "    return (transition_matrix, bigram_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word to index number\n",
    "def create_word_dict(sentences):\n",
    "\n",
    "    idx = 0\n",
    "    word_dict={}\n",
    "    # word_dict[\"<start>\"]=idx\n",
    "    for sentence in sentences:\n",
    "        for tup in sentence:\n",
    "            if tup[0] not in word_dict:\n",
    "                \n",
    "                word_dict[tup[0]]=idx\n",
    "                idx += 1\n",
    "    word_dict[\"<unknown>\"]=idx\n",
    "    # print('idx--------------------------------', idx)\n",
    "    # print('worddict--------------------------------', len(word_dict))\n",
    "    return word_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emmision_matrix(word_dict, tags_dict, tag_count, sentences):\n",
    "    # words = list(brown.words())\n",
    "    words_cnt = len(word_dict)\n",
    "    total_tags = len(tags_dict)\n",
    "    emmision_matrix = []\n",
    "    \n",
    "    for i in range(words_cnt):\n",
    "        emmision_matrix.append([0]*total_tags)\n",
    "    # print(\"--------------------------------------\",len(word_dict))\n",
    "    # print(\"------------------------\", len(emmision_matrix))\n",
    "    # print(\"------------------------\", word_dict['<unknown>'])\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        for j in sentence:\n",
    "            emmision_matrix[word_dict[j[0]]][tags_dict[j[1]]]+=1\n",
    "\n",
    "    \n",
    "    for i in range(words_cnt):\n",
    "        for j in range(total_tags):\n",
    "            emmision_matrix[i][j]/=tag_count[j]\n",
    "    # print(\"------------------------\", emmision_matrix[word_dict['unknown'])\n",
    "\n",
    "    # handling missing case\n",
    "    aux=[0]*len(tags_dict.keys())\n",
    "    aux[tags_dict['NOUN']]=0.5\n",
    "    aux[tags_dict['VERB']]=0.25\n",
    "    aux[tags_dict['ADV']]=0.125\n",
    "    aux[tags_dict['ADJ']]=0.125\n",
    "    # print(aux)\n",
    "    emmision_matrix[word_dict['<unknown>']]=aux\n",
    "    \n",
    "\n",
    "    return emmision_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(sentence):\n",
    "    new_sentence=[]\n",
    "    for i in sentence:\n",
    "        new_sentence.append(i[0])\n",
    "\n",
    "    # print(new_sentence)\n",
    "\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMM_logic(input, transition_matrix, emmision_matrix, tags_dict, word_dict):\n",
    "    print(tags_dict)\n",
    "    tags_output=[\"<start>\"]\n",
    "    last_prob = 1\n",
    "    viterbi=[]\n",
    "    for i in range(len(tags_dict)):\n",
    "        viterbi.append(([0])*len(input))\n",
    "    \n",
    "    viterbi[tags_dict[\"<start>\"]][0]=1\n",
    "    \n",
    "    for i in range(1, len(input)):\n",
    "        word_prob=0\n",
    "        tags=\"\"\n",
    "        curr_ob = input[i]\n",
    "        if curr_ob not in word_dict:\n",
    "            curr_ob=\"<unknown>\"\n",
    "        for curr_tag in tags_dict:\n",
    "            max_prob=0\n",
    "            for prev_tag in tags_dict:\n",
    "                 temp = transition_matrix[tags_dict[prev_tag]][tags_dict[curr_tag]]*emmision_matrix[word_dict[curr_ob]][tags_dict[curr_tag]]*viterbi[tags_dict[prev_tag]][i-1]\n",
    "                 if temp>max_prob:\n",
    "                     max_prob=temp\n",
    "            viterbi[tags_dict[curr_tag]][i]=max_prob\n",
    "            if max_prob>word_prob:\n",
    "                word_prob=max_prob\n",
    "                tags=curr_tag\n",
    "        if tags=='':\n",
    "            tags='X'\n",
    "        tags_output.append(tags)\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    return tags_output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_original = brown.tagged_sents(tagset='universal')\n",
    "sentences = add_start_end_tag(sentences_original)\n",
    "# (tags_dict, tags_reverse, tag_count) = creat_tags_meta(sentences)\n",
    "# (transition_matrix, bigram_matrix) = create_transition_matrix(sentences, tags_dict, tag_count)\n",
    "# word_dict = create_word_dict(sentences)\n",
    "# emmision_matrix = create_emmision_matrix(word_dict, tags_dict, tag_count, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confusion_matrix(cm,actual,predicted,tags_dict):\n",
    "    for i in range(len(actual)):\n",
    "        cm[tags_dict[actual[i][1]]][tags_dict[predicted[i]]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input=[\"<start>\",\"do\",\"you\",\"know\",\"who\",\"is\",\"vartul\", \"?\", \"<end>\"]\n",
    "# tags_output = HMM_logic(input, transition_matrix, emmision_matrix, tags_dict, word_dict)\n",
    "# print(tags_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits data in k sets:\n",
    "def k_splits (k, data):\n",
    "    splits = {}\n",
    "    n = len(data)//k\n",
    "    for i in range(0, k):\n",
    "        i = int(i)\n",
    "        if(i+1 == k):\n",
    "            splits[i]= data[n*i : ]\n",
    "        splits[i]=data[n*i : n*(i+1)]\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11468, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 29294, 3, 10, 14, 0, 34, 34, 183, 7, 0, 1465, 0, 4], [0, 452, 7685, 0, 3, 0, 64, 0, 0, 0, 0, 0, 0, 0], [0, 43, 0, 34765, 2162, 0, 0, 0, 15, 132, 0, 4, 0, 7], [0, 13, 4, 1175, 64553, 1, 13, 0, 35, 851, 0, 28, 83, 34], [0, 0, 0, 0, 0, 30110, 0, 0, 0, 0, 0, 0, 0, 5], [0, 211, 26, 0, 1, 0, 29202, 9, 1, 0, 0, 1, 0, 4], [0, 1, 0, 0, 0, 0, 10, 7633, 17, 0, 0, 0, 0, 1], [0, 496, 1, 24, 190, 0, 50, 29, 9482, 579, 0, 119, 0, 1], [0, 21, 0, 151, 1906, 0, 0, 0, 602, 16223, 0, 32, 4, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11466, 0, 0, 2], [0, 1278, 2, 12, 32, 0, 0, 0, 19, 67, 0, 4380, 0, 1], [0, 0, 0, 11, 445, 0, 0, 0, 0, 0, 0, 0, 3517, 1], [0, 0, 0, 1, 200, 1, 3, 0, 0, 3, 0, 0, 0, 73]]\n",
      "[[11468, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 30171, 5, 0, 0, 152, 0, 0, 0, 3, 0, 46, 0, 7], [0, 21, 58710, 712, 1020, 9, 0, 0, 51, 0, 4, 2, 107, 47], [0, 0, 1950, 16946, 126, 13, 0, 0, 586, 0, 56, 1, 0, 6], [0, 0, 2699, 138, 35104, 30, 0, 0, 13, 0, 2, 0, 0, 14], [0, 49, 17, 20, 8, 30332, 0, 0, 212, 29, 1588, 4, 1, 15], [0, 0, 0, 0, 0, 0, 29721, 0, 0, 0, 0, 0, 0, 16], [0, 0, 0, 0, 0, 0, 0, 11465, 0, 0, 0, 0, 0, 3], [0, 66, 201, 783, 29, 640, 0, 0, 10166, 18, 124, 1, 0, 1], [0, 46, 0, 0, 0, 0, 0, 0, 44, 8548, 0, 0, 0, 3], [0, 0, 21, 65, 2, 1211, 0, 0, 16, 0, 4369, 0, 0, 1], [0, 119, 9, 0, 3, 459, 0, 0, 0, 0, 0, 7995, 0, 1], [0, 0, 372, 0, 8, 0, 0, 0, 0, 0, 0, 0, 2734, 2], [0, 1, 199, 5, 1, 0, 0, 0, 0, 0, 0, 1, 0, 57]]\n",
      "[[11468, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 32651, 16, 0, 2, 173, 0, 0, 0, 5, 0, 29, 0, 23], [0, 69, 66406, 690, 1069, 0, 0, 0, 13, 0, 18, 4, 136, 65], [0, 0, 2665, 18491, 197, 10, 0, 0, 491, 0, 127, 0, 0, 22], [0, 0, 2107, 102, 38256, 26, 0, 0, 15, 0, 1, 0, 0, 28], [0, 50, 56, 12, 31, 36257, 20, 0, 196, 40, 1851, 12, 0, 31], [0, 0, 4, 0, 0, 0, 30685, 0, 0, 0, 0, 0, 0, 31], [0, 0, 0, 0, 0, 0, 0, 11458, 0, 0, 0, 0, 0, 10], [0, 67, 251, 772, 20, 613, 0, 0, 10271, 13, 94, 0, 0, 4], [0, 48, 2, 0, 0, 1, 0, 0, 29, 9230, 0, 0, 0, 8], [0, 0, 19, 55, 3, 1212, 0, 0, 21, 0, 4368, 2, 0, 5], [0, 100, 19, 1, 1, 372, 0, 0, 0, 0, 0, 7596, 0, 0], [0, 0, 445, 1, 17, 0, 0, 0, 0, 0, 0, 0, 4033, 2], [0, 13, 263, 5, 27, 16, 1, 0, 5, 4, 1, 6, 0, 104]]\n",
      "[[11468, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 23917, 2, 0, 0, 259, 0, 0, 2, 9, 0, 57, 0, 5], [0, 12, 44220, 445, 746, 11, 0, 0, 33, 1, 3, 5, 92, 17], [0, 0, 1299, 11299, 152, 18, 0, 0, 430, 0, 35, 0, 0, 5], [0, 0, 1565, 79, 33092, 26, 0, 0, 17, 0, 5, 0, 0, 12], [0, 34, 14, 22, 36, 22664, 0, 0, 208, 23, 1438, 6, 0, 8], [0, 0, 0, 0, 0, 0, 27905, 0, 0, 0, 0, 0, 0, 5], [0, 0, 0, 0, 0, 0, 0, 11467, 0, 0, 0, 0, 0, 1], [0, 85, 216, 522, 36, 532, 0, 0, 9192, 20, 225, 2, 0, 5], [0, 14, 0, 0, 0, 1, 0, 0, 14, 6524, 0, 0, 0, 3], [0, 0, 94, 65, 4, 1033, 0, 0, 24, 0, 4933, 0, 0, 2], [0, 304, 7, 0, 2, 270, 0, 0, 0, 0, 0, 10086, 0, 2], [0, 0, 200, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2010, 2], [0, 2, 149, 1, 1, 11, 22, 0, 0, 0, 0, 0, 5, 24]]\n",
      "[[11468, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 19663, 10, 0, 0, 314, 0, 0, 13, 9, 0, 16, 2, 3], [0, 2, 32612, 505, 681, 8, 0, 0, 32, 2, 15, 1, 151, 21], [0, 0, 938, 8437, 99, 6, 0, 0, 358, 0, 16, 0, 0, 1], [0, 0, 1473, 90, 30639, 41, 0, 0, 42, 0, 2, 0, 0, 4], [0, 15, 22, 37, 42, 16681, 0, 0, 291, 22, 1320, 0, 0, 4], [0, 0, 0, 0, 0, 0, 29080, 0, 0, 0, 0, 0, 0, 3], [0, 0, 0, 0, 0, 0, 0, 11465, 0, 0, 0, 0, 0, 3], [0, 98, 257, 550, 38, 416, 0, 0, 8594, 47, 299, 0, 0, 0], [0, 16, 8, 0, 0, 0, 0, 0, 1, 5949, 0, 0, 0, 0], [0, 2, 166, 36, 19, 915, 0, 0, 23, 0, 5349, 1, 0, 2], [0, 575, 5, 0, 2, 222, 0, 0, 3, 0, 7, 12970, 0, 0], [0, 0, 15, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1056, 0], [0, 0, 147, 2, 7, 1, 0, 0, 0, 0, 1, 0, 0, 23]]\n"
     ]
    }
   ],
   "source": [
    "cross_validation_set=k_splits(5,sentences)\n",
    "keys=list(cross_validation_set.keys())\n",
    "\n",
    "for i in keys:\n",
    "    train_data=[]\n",
    "    for k in cross_validation_set.keys():\n",
    "        if k!=i:\n",
    "            train_data+=cross_validation_set[k]\n",
    "\n",
    "    test_data=cross_validation_set[i]\n",
    "    # print(test_data[1:20])\n",
    "    # break\n",
    "    (tags_dict, tags_reverse, tag_count) = creat_tags_meta(train_data)\n",
    "    confusion_matrix=[]\n",
    "    for i in range(len(tag_count)):\n",
    "        confusion_matrix.append([0]*len(tag_count))\n",
    "    # print(tags_dict)\n",
    "    (transition_matrix, bigram_matrix) = create_transition_matrix(train_data, tags_dict, tag_count)\n",
    "    word_dict = create_word_dict(train_data)\n",
    "    emmision_matrix = create_emmision_matrix(word_dict,  tags_dict, tag_count, train_data)\n",
    "    # c=0\n",
    "    for sen in test_data:\n",
    "        # if c == 10:\n",
    "        #     break\n",
    "        # c+=1\n",
    "        # print(remove_tags(sen))\n",
    "        tags_output = HMM_logic(remove_tags(sen), transition_matrix, emmision_matrix, tags_dict, word_dict)\n",
    "        # print(sen,tags_output)\n",
    "        # print(len(remove_tags(sen)),len(tags_output))\n",
    "        build_confusion_matrix(confusion_matrix,sen,tags_output,tags_dict)\n",
    "        \n",
    "    print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9486702986081903\n"
     ]
    }
   ],
   "source": [
    "actual=0\n",
    "count=0\n",
    "for i in range(0,len(confusion_matrix)):\n",
    "    actual+=confusion_matrix[i][i]\n",
    "    count+=sum(confusion_matrix[i])\n",
    "actual/=5\n",
    "count/=5\n",
    "print(actual/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(confusion_matrix):\n",
    "    recall = []\n",
    "    n = len(confusion_matrix)\n",
    "    for i in range(0,n):\n",
    "        sum = 0\n",
    "        for j in range(0,len(confusion_matrix[i])):\n",
    "            sum+=confusion_matrix[i][j]\n",
    "        recall.append(confusion_matrix[i][i]/sum)\n",
    "\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(confusion_matrix):\n",
    "    precision = []\n",
    "    n = len(confusion_matrix)\n",
    "    for i in range(0,n):\n",
    "        sum = 0\n",
    "        for j in range(0,len(confusion_matrix[i])):\n",
    "            sum+=confusion_matrix[j][i]\n",
    "        precision.append(confusion_matrix[i][i]/sum)\n",
    "\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall :  [1.0, 0.9816774837743385, 0.9583308845136644, 0.8561136478944699, 0.9488402341209625, 0.9049039817728111, 0.9998968469552659, 0.9997384025113359, 0.834449946596757, 0.9958151991965183, 0.8212805158912944, 0.9409460243760882, 0.9850746268656716, 0.1270718232044199]\n"
     ]
    }
   ],
   "source": [
    "print(\"recall : \", recall(confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  [1.0, 0.9652447106180354, 0.9147056348694359, 0.8736667702184944, 0.9718028419182948, 0.896635132229628, 1.0, 1.0, 0.9184567703323715, 0.9867308011278819, 0.7631616493080325, 0.9986141053279951, 0.8734491315136477, 0.359375]\n"
     ]
    }
   ],
   "source": [
    "print(\"precision : \", precision(confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<start>': 0, 'DET': 1, 'NOUN': 2, 'ADJ': 3, 'VERB': 4, 'ADP': 5, '.': 6, '<end>': 7, 'ADV': 8, 'CONJ': 9, 'PRT': 10, 'PRON': 11, 'NUM': 12, 'X': 13}\n",
      "['<start>', 'ADP', 'PRON', 'VERB', 'VERB', 'ADV', 'ADV', 'DET', 'NOUN', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PRON', 'VERB', 'ADV', 'ADJ', 'PRT', 'VERB', '.', '<end>']\n"
     ]
    }
   ],
   "source": [
    "input=[\"<start>\", \"Although\", \"it\", \"was\", \"raining\", \"heavily\", \"outside\", \"the\", \"children\", \"decided\", \"to\", \"continue\", \"their\", \"game\", \"of\", \"soccer\", \"in\", \"the\", \"park\", \"until\", \"it\", \"became\", \"too\", \"dark\", \"to\", \"see\", \".\", \"<end>\"]\n",
    "tags_output= HMM_logic(input, transition_matrix, emmision_matrix, tags_dict, word_dict)\n",
    "print(tags_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
